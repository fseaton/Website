---
title: Analysis of Variance
author: Fiona Seaton
date: 2018-03-28

draft: false
toc: false
type: docs

linktitle: ANOVAs
menu:
  tutorial:
    parent: Modelling
    weight: 6
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

This tutorial is the second part of the introduction to simple linear regression in R, the use of ANOVAs with categorical predictors.

First we're going to load in all the packages we'll be using in this analysis.

```{r packages}
library(agridat)          # a package of agricultural datasets
library(summarytools)     # useful functions for summarising datasets
library(dplyr)            # manipulating data
library(ggplot2)          # plotting
library(gridExtra)        # plotting in panels
library(car)              # extensions for regression
library(AICcmodavg)       # calculates AICc
```

As we're plotting with ggplot I'm going to set the theme now for the whole tutorial to make it look nicer to me - see the plotting tutorial for more information on the plotting commands.
```{r theme_set}
theme_set(theme_bw() + theme(panel.grid = element_blank()))
```

We're going to be using the apples data from the agridat package, an experiment from the 1980s on the impact of spacing, root stock and cultivars on apple tree yields. We'll be focusing on the impact of spacing, which came in three different treatments: 6m, 10m and 14m apart.

```{r examine apples}
apples <- agridat::archbold.apple
head(apples)
str(apples)

print(dfSummary(apples), method = "render")

```


So do apples that are closer together have lower yield? There are only 3 spacing values so we'll convert it to a categorical variable using as.factor.

```{r apples spacing}
apples$spacing2 <- as.factor(apples$spacing)

ggplot(apples, aes(spacing2, yield)) +
    geom_boxplot() +
    labs(x = "Spacing (m)", y = "Yield (kg)")

```


Within R lm and aov give the same result with a single categorical predictor only difference is output of summary functions, which can be changed using summary.lm and summary.aov

now run linear model with lm to see if difference is statistically significant
```{r apples lm}
apples.m <- lm(yield ~ spacing2, data = apples)
summary(apples.m)

```

output gives the difference between the 10m spacing and the 6m spacing, and the 14m spacing and the 6m spacing. The 6m spacing is given by the intercept

use plots to examine residuals. 
```{r apples diagnostics}
par(mfrow=c(2,2));plot(apples.m);par(mfrow=c(1,1)) 
qqp(apples.m)

```


If wish to do a Tukey's HSD post-hoc test then need to fit model with aov rather than lm
```{r Tukey HSD}
apples.aov <- aov(yield ~ spacing2, data = apples)
summary(apples.aov)
summary(apples.m) # compare to lm output - different format but same numbers
summary.lm(apples.aov) # can get equivalent output to lm using summary.lm

TukeyHSD(apples.aov)

```





### ANOVA with unbalanced designs and > 1 predictor

Balanced designs have the same number of reps per treatment. This is often not the case, and the study is unbalanced. If the study is unbalanced the way in which predictors are evaluated impacts the result. The different ways of evaluating predictors are known as Type I, Type II and Type III ANOVAs

To find out more about this go to http://goanna.cs.rmit.edu.au/~fscholer/anova.php

For type III tests to be correct need to change the way R codes factors

```{r options factors}
options(contrasts = c("contr.sum", "contr.poly")) 

```

This won't change type I or II
Default is: options(contrasts = c("contr.treatment", "contr.poly"))

```{r fake data}
A        = c("a", "a", "a", "a", "b", "b", "b", "b", "b", "b", "b", "b")
B        = c("x", "y", "x", "y", "x", "y", "x", "y", "x", "x", "x", "x")
C        = c("l", "l", "m", "m", "l", "l", "m", "m", "l", "l", "l", "l")
response = c( 14,  30,  15,  35,  50,  51,  30,  32,  51,  55,  53,  55)

```

```{r model}
model = lm(response ~ A + B + C + A:B + A:C + B:C)

anova(model)              # Type I tests

Anova(model, type="II")   # Type II tests using car package

Anova(model, type="III")  # Type III tests using car package

```



Balanced design shows no difference between type I, II and III

```{r fake unbalanced data}
A        = c("a", "a", "a", "a", "a", "a", "b", "b", "b", "b", "b", "b")
B        = c("x", "y", "x", "y", "x", "y", "x", "y", "x", "y", "x", "y")
C        = c("l", "l", "m", "m", "l", "l", "m", "m", "l", "l", "m", "m")
response = c( 14,  30,  15,  35,  50,  51,  30,  32,  51,  55,  53,  55)

```

```{r}
model = lm(response ~ A + B + C + A:B + A:C + B:C)

anova(model)              # Type I tests

Anova(model, type="II")   # Type II tests

Anova(model, type="III")  # Type III tests 

```



The choice between the types of ANOVAs is beyond the scope of this R club and is hypothesis dependent.
