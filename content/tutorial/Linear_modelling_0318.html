---
title: Linear modelling
author: Fiona Seaton
date: 2018-03-28

draft: false
toc: false
type: docs

linktitle: Linear modelling
menu:
  tutorial:
    parent: Modelling
    weight: 5
---



<p>This tutorial is an introduction to simple linear regression in R, I’ve split it into two parts: this part is on modelling with numeric predictors.</p>
<p>First we’re going to load in all the packages we’ll be using in this analysis.</p>
<pre class="r"><code>library(agridat)          # a package of agricultural datasets
library(summarytools)     # useful functions for summarising datasets
library(psych)            # more functions for examining datasets
library(dplyr)            # manipulating data
library(ggplot2)          # plotting
library(gridExtra)        # plotting in panels
library(car)              # extensions for regression
library(AICcmodavg)       # calculates AICc</code></pre>
<p>As we’re plotting with ggplot I’m going to set the theme now for the whole tutorial to make it look nicer to me - see the plotting tutorial for more information on the plotting commands.</p>
<pre class="r"><code>theme_set(theme_bw() + theme(panel.grid = element_blank()))</code></pre>
<div id="numerical-predictors" class="section level2">
<h2>Numerical predictors</h2>
<p>We’re going to be using data from an experiment in 1952-3 looking at the impact of fertiliser application upon corn, clover and alfafa yields. A copy of the data is held in the agridat package, and the original analysis is linked to on the help page for the dataset. We’re going to read it in and take a quick look at it using the summarytools package:</p>
<pre class="r"><code>Fert &lt;- heady.fertilizer
# examining dataset using summarytools functions
print(dfSummary(Fert, style = &#39;grid&#39;, graph.magnif = 0.85), method = &quot;render&quot;, omit.headings = TRUE)</code></pre>
<div class="container st-container">
<table class="table table-striped table-bordered st-table st-table-striped st-table-bordered st-multiline ">
  <thead>
    <tr>
      <th align="center"><strong>No</strong></th>
      <th align="center"><strong>Variable</strong></th>
      <th align="center"><strong>Stats / Values</strong></th>
      <th align="center"><strong>Freqs (% of Valid)</strong></th>
      <th align="center"><strong>Graph</strong></th>
      <th align="center"><strong>Valid</strong></th>
      <th align="center"><strong>Missing</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td align="center">1</td>
      <td align="left">crop
[factor]</td>
      <td align="left">1. alfalfa
2. clover
3. corn
4. corn2</td>
      <td align="left">162 (25.0%)
162 (25.0%)
162 (25.0%)
162 (25.0%)</td>
      <td align="center" border="0"><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAH8AAABYCAMAAADrytivAAAADFBMVEX9/v2mpqb39/f9/v0TNkn1AAAABHRSTlP///8AQCqp9AAAAGxJREFUaIHt1sENgEAMA8GD679n6GIfnjQwUuTHntvemfef9H7/DY/P5/P5fP6mH/dP3X+1X/8/3x+fz+fz+fw9P+6fuv9qv/5/vj8+n8/n8/l7ftw/df/Vfv3/fH98Pp/P5/P3/Lh/6v7b9j/DyFkZKouMzwAAAABJRU5ErkJggg=="></td>
      <td align="center">648
(100%)</td>
      <td align="center">0
(0%)</td>
    </tr>
    <tr>
      <td align="center">2</td>
      <td align="left">rep
[integer]</td>
      <td align="left">mean (sd) : 1.5 (0.5)
min &lt; med &lt; max :
1 &lt; 1.5 &lt; 2
IQR (CV) : 1 (0.33)</td>
      <td align="left">1 : 324 (50.0%)
2 : 324 (50.0%)</td>
      <td align="center" border="0"><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAH8AAAAsCAMAAAB7eZd4AAAADFBMVEX9/v2mpqb39/f9/v0TNkn1AAAABHRSTlP///8AQCqp9AAAAEZJREFUWIXt1rkNADAMxLA8+++cbKHCvAUIGC60bruV+zvd9084Pp/P5/P5M/24f+r+q/36/vn/8fl8Pp/Pn+fH/VP3X7sHQS4sjbFMW2oAAAAASUVORK5CYII="></td>
      <td align="center">648
(100%)</td>
      <td align="center">0
(0%)</td>
    </tr>
    <tr>
      <td align="center">3</td>
      <td align="left">P
[integer]</td>
      <td align="left">mean (sd) : 160 (103.36)
min &lt; med &lt; max :
0 &lt; 160 &lt; 320
IQR (CV) : 160 (0.65)</td>
      <td align="left">0 : 72 (11.1%)
40 : 72 (11.1%)
80 : 72 (11.1%)
120 : 72 (11.1%)
160 : 72 (11.1%)
200 : 72 (11.1%)
240 : 72 (11.1%)
280 : 72 (11.1%)
320 : 72 (11.1%)</td>
      <td align="center" border="0"><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAH8AAADGCAMAAADMpq+cAAAADFBMVEX9/v2mpqb39/f9/v0TNkn1AAAABHRSTlP///8AQCqp9AAAAM1JREFUeJzt1rENwDAMBDEn3n/nZApdIXoBAvIXd277Dp/PD/0nfb//ho/P5/P5fH7jx/1R91ft1/fP98fn8/l8Pn/ej/uj7q/tfv3/+f75fD6fz+fP+3F/1P1V+/X98/3x+Xw+n8/f58f9U/df7df3z/fH5/P5fD5/3o/7o+6v7X79//n++Xw+n8/nz/txf9T9Vfv1/fP98fl8Pp/P3+fH/VP3X+3X98/3x+fz+Xw+f96P+6Pur+1+/f/5/vl8Pp/P58/7cX/U/cXn7/U/KfrL9wb8s/8AAAAASUVORK5CYII="></td>
      <td align="center">648
(100%)</td>
      <td align="center">0
(0%)</td>
    </tr>
    <tr>
      <td align="center">4</td>
      <td align="left">K
[integer]</td>
      <td align="left">mean (sd) : 80 (108.4)
min &lt; med &lt; max :
0 &lt; 0 &lt; 320
IQR (CV) : 160 (1.36)</td>
      <td align="left">0 : 360 (55.6%)
40 : 36 (5.6%)
80 : 36 (5.6%)
120 : 36 (5.6%)
160 : 36 (5.6%)
200 : 36 (5.6%)
240 : 36 (5.6%)
280 : 36 (5.6%)
320 : 36 (5.6%)</td>
      <td align="center" border="0"><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAH8AAADGCAMAAADMpq+cAAAADFBMVEX9/v2mpqb39/f9/v0TNkn1AAAABHRSTlP///8AQCqp9AAAALpJREFUeJzt1rkRgAAMA0Ge/nuGEBrwBV43sDOyAh13ewefzw/9M73Xv8Lj8/l8Pp/f+PH+qPdX7f/iKPxvHfh8Pp/P5+/w4/3RHr/+f95/Pp/P5/P58779mfp1/nn/+Hw+n8/n7/Ptz9Sv88/7x+fz+Xw+f963/1b79f/z/vP5fD6fz5/37c/Ur/PP+8fn8/l8Pn+fb3+mfp1/3j8+n8/n8/nzvv232q//n/efz+fz+Xz+vG9/8vlL/Qft0BOIADkroQAAAABJRU5ErkJggg=="></td>
      <td align="center">648
(100%)</td>
      <td align="center">0
(0%)</td>
    </tr>
    <tr>
      <td align="center">5</td>
      <td align="left">N
[integer]</td>
      <td align="left">mean (sd) : 80 (108.4)
min &lt; med &lt; max :
0 &lt; 0 &lt; 320
IQR (CV) : 160 (1.36)</td>
      <td align="left">0 : 360 (55.6%)
40 : 36 (5.6%)
80 : 36 (5.6%)
120 : 36 (5.6%)
160 : 36 (5.6%)
200 : 36 (5.6%)
240 : 36 (5.6%)
280 : 36 (5.6%)
320 : 36 (5.6%)</td>
      <td align="center" border="0"><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAH8AAADGCAMAAADMpq+cAAAADFBMVEX9/v2mpqb39/f9/v0TNkn1AAAABHRSTlP///8AQCqp9AAAALpJREFUeJzt1rkRgAAMA0Ge/nuGEBrwBV43sDOyAh13ewefzw/9M73Xv8Lj8/l8Pp/f+PH+qPdX7f/iKPxvHfh8Pp/P5+/w4/3RHr/+f95/Pp/P5/P58779mfp1/nn/+Hw+n8/n7/Ptz9Sv88/7x+fz+Xw+f963/1b79f/z/vP5fD6fz5/37c/Ur/PP+8fn8/l8Pn+fb3+mfp1/3j8+n8/n8/nzvv232q//n/efz+fz+Xz+vG9/8vlL/Qft0BOIADkroQAAAABJRU5ErkJggg=="></td>
      <td align="center">648
(100%)</td>
      <td align="center">0
(0%)</td>
    </tr>
    <tr>
      <td align="center">6</td>
      <td align="left">yield
[numeric]</td>
      <td align="left">mean (sd) : 31.46 (42.3)
min &lt; med &lt; max :
1.14 &lt; 4.19 &lt; 144.9
IQR (CV) : 44.4 (1.34)</td>
      <td align="left">326 distinct values</td>
      <td align="center" border="0"><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAH8AAABVCAMAAABXVMtxAAAADFBMVEX9/v2mpqby8vL9/v28xacEAAAABHRSTlP///8AQCqp9AAAAINJREFUaIHt2kEKgCAQBVCr+9+5XZCIaegI9f5WmacyrjQda5P46/0tS7i/38Ln8/l8Pp/P5/P5fD6fz+fz+Xw+n8/n8/l8/if8wOf4oh94HPwP+w2NPNd/LtTiv76Ng/zaarKa2eAMv1qzZ+4Yv7bjCL9n7t/9QusW/58F5fIX5u/+CauHdM8b5y+CAAAAAElFTkSuQmCC"></td>
      <td align="center">456
(70.37%)</td>
      <td align="center">192
(29.63%)</td>
    </tr>
  </tbody>
</table>
<p>Generated by <a href='https://github.com/dcomtois/summarytools'>summarytools</a> 0.8.8 (<a href='https://www.r-project.org/'>R</a> version 3.5.1)<br/>2018-11-22</p>
</div>
<p>The different crops are all probably quite different in their responses, so we’re going to look at the summary statistics by group (again using the summarytools package, see the summary statistics tutorial for more methods).</p>
<pre class="r"><code># First save the results
by(data = Fert, 
   INDICES = Fert$crop, 
   FUN = descr, stats = c(&quot;mean&quot;, &quot;sd&quot;, &quot;min&quot;, &quot;med&quot;, &quot;max&quot;), 
   transpose = TRUE, style = &quot;rmarkdown&quot;, omit.headings = TRUE)</code></pre>
<pre><code>## Fert$crop: alfalfa
##   
## **Group:** crop = alfalfa     
## **N:** 162   
## 
## |    &amp;nbsp; |   Mean | Std.Dev |  Min | Median |    Max |
## |----------:|-------:|--------:|-----:|-------:|-------:|
## |   **rep** |   1.50 |    0.50 | 1.00 |   1.50 |   2.00 |
## |     **P** | 160.00 |  103.60 | 0.00 | 160.00 | 320.00 |
## |     **K** | 160.00 |  103.60 | 0.00 | 160.00 | 320.00 |
## |     **N** |   0.00 |    0.00 | 0.00 |   0.00 |   0.00 |
## | **yield** |   3.30 |    0.51 | 1.14 |   3.49 |   4.02 |
## -------------------------------------------------------- 
## Fert$crop: clover
##   
## **Group:** crop = clover     
## **N:** 162   
## 
## |    &amp;nbsp; |   Mean | Std.Dev |  Min | Median |    Max |
## |----------:|-------:|--------:|-----:|-------:|-------:|
## |   **rep** |   1.50 |    0.50 | 1.00 |   1.50 |   2.00 |
## |     **P** | 160.00 |  103.60 | 0.00 | 160.00 | 320.00 |
## |     **K** | 160.00 |  103.60 | 0.00 | 160.00 | 320.00 |
## |     **N** |   0.00 |    0.00 | 0.00 |   0.00 |   0.00 |
## | **yield** |   3.45 |    0.40 | 2.29 |   3.54 |   4.31 |
## -------------------------------------------------------- 
## Fert$crop: corn
##   
## **Group:** crop = corn     
## **N:** 162   
## 
## |    &amp;nbsp; |   Mean | Std.Dev |  Min | Median |    Max |
## |----------:|-------:|--------:|-----:|-------:|-------:|
## |   **rep** |   1.50 |    0.50 | 1.00 |   1.50 |   2.00 |
## |     **P** | 160.00 |  103.60 | 0.00 | 160.00 | 320.00 |
## |     **K** |   0.00 |    0.00 | 0.00 |   0.00 |   0.00 |
## |     **N** | 160.00 |  103.60 | 0.00 | 160.00 | 320.00 |
## | **yield** |  86.07 |   46.35 | 4.20 | 106.35 | 144.90 |
## -------------------------------------------------------- 
## Fert$crop: corn2
##   
## **Group:** crop = corn2     
## **N:** 162   
## 
## |    &amp;nbsp; |   Mean | Std.Dev |  Min | Median |    Max |
## |----------:|-------:|--------:|-----:|-------:|-------:|
## |   **rep** |   1.50 |    0.50 | 1.00 |   1.50 |   2.00 |
## |     **P** | 160.00 |  103.60 | 0.00 | 160.00 | 320.00 |
## |     **K** |   0.00 |    0.00 | 0.00 |   0.00 |   0.00 |
## |     **N** | 160.00 |  103.60 | 0.00 | 160.00 | 320.00 |
## | **yield** |  33.03 |   21.29 | 3.70 |  28.45 |  76.70 |</code></pre>
<p>We’re going to treat the fertiliser treatments as numeric as there are sufficient different treatments to fit linear regression, and for ease of interpretation.</p>
<p>Let’s take the response of clover to fertilisation, first we’ll filter out the rows that correspond to clover and use droplevels to get rid of the empty levels within the crop variable. We’ll use pairs.panels from the psych package to take a quick look at the relationships between the variables.</p>
<pre class="r"><code>clover &lt;- filter(Fert, crop == &quot;clover&quot;)
clover &lt;- droplevels(clover)
pairs.panels(clover[,c(2,3,4,6)])</code></pre>
<p><img src="/tutorial/Linear_modelling_0318_files/figure-html/examine%20clover-1.png" width="672" /></p>
<p>We can see there is no correlation between the treatments, as expected as this experiment was designed that way. There was no nitrogen added to the clover crops as clover is nitrogen fixing so we’re only looking at the impact of P and K fertiliser addition. We’ll plot more detailed plots of the yield against the P and K fertiliser use using ggplot.</p>
<pre class="r"><code>(Pplot &lt;- ggplot(clover, aes(x=P, y=yield)) +
    geom_point() +
    labs(x = &quot;Phosphorus (pounds/acre)&quot;, y = &quot;Yield (tons/acre)&quot;) +
    geom_smooth(method=&quot;lm&quot;))</code></pre>
<p><img src="/tutorial/Linear_modelling_0318_files/figure-html/plotting%20clover%20yield-1.png" width="672" /></p>
<pre class="r"><code>(Kplot &lt;- ggplot(clover, aes(x=K, y=yield)) +
    geom_point() +
    labs(x = &quot;Potassium (pounds/acre)&quot;, y = &quot;Yield (tons/acre)&quot;) +
    geom_smooth(method=&quot;lm&quot;))</code></pre>
<p><img src="/tutorial/Linear_modelling_0318_files/figure-html/plotting%20clover%20yield-2.png" width="672" /></p>
<pre class="r"><code>grid.arrange(Pplot, Kplot, nrow=1)</code></pre>
<p><img src="/tutorial/Linear_modelling_0318_files/figure-html/plotting%20clover%20yield-3.png" width="672" /></p>
<p>Now we want to fit our linear model and see if yield increases with fertiliser use. First we’re going to fit each fertiliser treatment separately, for demonstratory purposes.</p>
<pre class="r"><code>cloverp.lm &lt;- lm(yield ~ P, clover)
summary(cloverp.lm)</code></pre>
<pre><code>## 
## Call:
## lm(formula = yield ~ P, data = clover)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.82080 -0.20802  0.00309  0.22818  1.03179 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 3.110801   0.053920  57.693  &lt; 2e-16 ***
## P           0.002093   0.000278   7.527 1.41e-11 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.3254 on 112 degrees of freedom
##   (48 observations deleted due to missingness)
## Multiple R-squared:  0.3359, Adjusted R-squared:   0.33 
## F-statistic: 56.65 on 1 and 112 DF,  p-value: 1.415e-11</code></pre>
<p>We can see from the bottom lines of the output that P fertiliser has a significant impact upon clover yield at p = 1.415e-11, the F statistic is usually reported as well. Here we’d say that F<sub>1,112</sub>=56.65. The R<sup>2</sup> value is 0.336, which seems promising for crop research!</p>
<p>Whenever you do a linear model make sure to check the assumptions! You can plot the model which will return four graphs: the qqplot, the residuals against fitted values, the standardised residuals against fitted values, and the leverage plot. We want the points in the qqplot to lie near the qqline, if they don’t then the assumption of normality of residuals is violated. If there residuals appear to change consistently with the fitted values then that could mean the assumption of homoscedasticity, or homogeneity of variance, is violated which can be a big problem in model fitting. Here I’ve used par to set graphical parameters so you get two four plots in a 2x2 matrix then reverted to the previous setting.</p>
<pre class="r"><code>par(mfrow=c(2,2));plot(cloverp.lm);par(mfrow=c(1,1))</code></pre>
<p><img src="/tutorial/Linear_modelling_0318_files/figure-html/clover%20p%20diagnostic-1.png" width="672" /></p>
<p>It can be difficult to interpret diagnostic plots sometimes, and I’ve found the qqp function within the car package very useful as it gives confidence intervals around the qqline so you can see more clearly which points are a problem.</p>
<pre class="r"><code>qqp(cloverp.lm)</code></pre>
<p><img src="/tutorial/Linear_modelling_0318_files/figure-html/car%20qqp%20cloverp-1.png" width="672" /></p>
<pre><code>## [1] 134 149</code></pre>
<p>Now we’re going to repeat the above for K fertiliser addition! First, model fitting:</p>
<pre class="r"><code>cloverk.lm &lt;- lm(yield ~ K, clover)
summary(cloverk.lm)</code></pre>
<pre><code>## 
## Call:
## lm(formula = yield ~ K, data = clover)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.02188 -0.20374  0.03939  0.23812  0.73065 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 3.3118757  0.0643688  51.452   &lt;2e-16 ***
## K           0.0008359  0.0003319   2.518   0.0132 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.3884 on 112 degrees of freedom
##   (48 observations deleted due to missingness)
## Multiple R-squared:  0.0536, Adjusted R-squared:  0.04515 
## F-statistic: 6.343 on 1 and 112 DF,  p-value: 0.0132</code></pre>
<p>There doesn’t appear to be much of an impact of K fertiliser on yield, p is significant but the R<sup>2</sup> is very low.</p>
<p>Now, model checking:</p>
<pre class="r"><code>par(mfrow=c(2,2));plot(cloverk.lm);par(mfrow=c(1,1))</code></pre>
<p><img src="/tutorial/Linear_modelling_0318_files/figure-html/clover%20k%20diagnostic-1.png" width="672" /></p>
<pre class="r"><code>qqp(cloverk.lm)</code></pre>
<p><img src="/tutorial/Linear_modelling_0318_files/figure-html/clover%20k%20diagnostic-2.png" width="672" /></p>
<pre><code>## [1]  2 92</code></pre>
<p>Now often we don’t expect a linear response, and we can fit polynomial models using lm. I’ll show you how to fit a quadratic function, there’s code in the heady.fertiliser help file that shows how they fit models with square root terms.</p>
<pre class="r"><code>cloverp.lm2 &lt;- lm(yield ~ I(P^2) + P, clover)
summary(cloverp.lm2)</code></pre>
<pre><code>## 
## Call:
## lm(formula = yield ~ I(P^2) + P, data = clover)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.60457 -0.17493 -0.03652  0.12533  0.93882 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  2.886e+00  5.722e-02  50.430  &lt; 2e-16 ***
## I(P^2)      -1.656e-05  2.513e-06  -6.589 1.54e-09 ***
## P            7.392e-03  8.384e-04   8.817 1.87e-14 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.2771 on 111 degrees of freedom
##   (48 observations deleted due to missingness)
## Multiple R-squared:  0.5226, Adjusted R-squared:  0.514 
## F-statistic: 60.76 on 2 and 111 DF,  p-value: &lt; 2.2e-16</code></pre>
<pre class="r"><code>par(mfrow=c(2,2));plot(cloverp.lm2);par(mfrow=c(1,1))</code></pre>
<p><img src="/tutorial/Linear_modelling_0318_files/figure-html/quadratic-1.png" width="672" /></p>
<pre class="r"><code>qqp(cloverp.lm2)</code></pre>
<p><img src="/tutorial/Linear_modelling_0318_files/figure-html/quadratic-2.png" width="672" /></p>
<pre><code>## [1] 134 149</code></pre>
<div id="two-predictors" class="section level3">
<h3>Two predictors</h3>
<p>Now this experiment involved adding the two fertilisers together and separately so we should be taking both treatments into account and fitting models with two predictors. First we can use an asterisk to estimate if there’s some kind of interaction effect between the predictors.</p>
<pre class="r"><code>cloverpk.lm &lt;- lm(yield ~ K*P, clover)
summary(cloverpk.lm)</code></pre>
<pre><code>## 
## Call:
## lm(formula = yield ~ K * P, data = clover)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.65579 -0.20341  0.00423  0.18278  0.86017 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  2.902e+00  9.213e-02  31.501  &lt; 2e-16 ***
## K            1.324e-03  4.811e-04   2.752  0.00693 ** 
## P            2.605e-03  4.811e-04   5.414 3.65e-07 ***
## K:P         -3.295e-06  2.497e-06  -1.319  0.18985    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.3136 on 110 degrees of freedom
##   (48 observations deleted due to missingness)
## Multiple R-squared:  0.3942, Adjusted R-squared:  0.3777 
## F-statistic: 23.86 on 3 and 110 DF,  p-value: 5.716e-12</code></pre>
<pre class="r"><code>par(mfrow=c(2,2));plot(cloverpk.lm);par(mfrow=c(1,1))</code></pre>
<p><img src="/tutorial/Linear_modelling_0318_files/figure-html/two%20predictors-1.png" width="672" /></p>
<pre class="r"><code>qqp(cloverpk.lm)</code></pre>
<p><img src="/tutorial/Linear_modelling_0318_files/figure-html/two%20predictors-2.png" width="672" /></p>
<pre><code>## [1]  42 149</code></pre>
<p>Here we can see that this model is significant at p &lt; 0.0001, and it has the highest R<sup>2</sup> yet! However notice that if you look at the coefficients the interaction effect (K:P) is low, and p = 0.19. We can try fitting the model without this interaction and see what happens:</p>
<pre class="r"><code>cloverpk.lm2 &lt;- lm(yield ~ K + P, clover)
summary(cloverpk.lm2)</code></pre>
<pre><code>## 
## Call:
## lm(formula = yield ~ K + P, data = clover)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.69566 -0.20316  0.00249  0.19212  0.90308 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 2.9856599  0.0670865  44.505  &lt; 2e-16 ***
## K           0.0007970  0.0002689   2.964  0.00371 ** 
## P           0.0020777  0.0002689   7.727  5.3e-12 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.3146 on 111 degrees of freedom
##   (48 observations deleted due to missingness)
## Multiple R-squared:  0.3846, Adjusted R-squared:  0.3735 
## F-statistic: 34.69 on 2 and 111 DF,  p-value: 1.983e-12</code></pre>
<pre class="r"><code>par(mfrow=c(2,2));plot(cloverpk.lm2);par(mfrow=c(1,1))</code></pre>
<p><img src="/tutorial/Linear_modelling_0318_files/figure-html/two%20predictors%20no%20interaction-1.png" width="672" /></p>
<pre class="r"><code>qqp(cloverpk.lm2)</code></pre>
<p><img src="/tutorial/Linear_modelling_0318_files/figure-html/two%20predictors%20no%20interaction-2.png" width="672" /></p>
<pre><code>## [1]  42 149</code></pre>
<p>This model looks fairly similar in R<sup>2</sup> to the previous, however it is better practice to compare models using an information criterion. Information criterions look at how much variation is explained by the model and then penalise for model complexity. Therefore if two models explain the same amount of variation then the simpler model will be preferred. One of the most common ICs is AIC (Aikake’s An Information Criterion). This is present in base R, but we’re going to use a version that works better with small sample sizes: AICc. We’ll use the AICcmodavg package to do this.</p>
<pre class="r"><code>AICc(cloverpk.lm)  </code></pre>
<pre><code>## [1] 65.58202</code></pre>
<pre class="r"><code>AICc(cloverpk.lm2) </code></pre>
<pre><code>## [1] 65.18282</code></pre>
<pre class="r"><code>AICc(cloverp.lm)</code></pre>
<pre><code>## [1] 71.71905</code></pre>
<pre class="r"><code>AICc(cloverk.lm)</code></pre>
<pre><code>## [1] 112.1038</code></pre>
<p>A commonly used rule of thumb is that if the AIC(c)’s are within 2 points of each other the models are essentially equivalent. We have a difference of 0.4 between the two models with both P and K as predictors so these are essentially equivalent. The model with P only is noticeably worse, and K doesn’t do well at all.</p>
<div id="one-more-diagnostic-check-for-models-with-multiple-predictors" class="section level4">
<h4>One more diagnostic check for models with multiple predictors!</h4>
<p>If the predictors are highly correlated then the model struggles to estimate impact and estimated error of coefficients will be high. VIF estimates the influence of multicollinearity on estimated variance of predictors.</p>
<pre class="r"><code>vif(cloverpk.lm2)</code></pre>
<pre><code>##        K        P 
## 1.000349 1.000349</code></pre>
<p>For more on vif see <a href="http://www.statisticshowto.com/variance-inflation-factor/" class="uri">http://www.statisticshowto.com/variance-inflation-factor/</a> Rough rules: VIF=1 not correlated; 1<VIF<5 moderately correlated; VIF>5 highly correlated. vif here is low, as we’d expect with a correlation coefficient of 0 between P and K</p>
</div>
</div>
</div>
